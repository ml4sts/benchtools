Traceback (most recent call last):
  File "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/jupyter_cache/executors/utils.py", line 58, in single_nb_execution
    executenb(
  File "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/nbclient/client.py", line 1323, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/jupyter_core/utils/__init__.py", line 165, in wrapped
    return loop.run_until_complete(inner)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/asyncio/base_events.py", line 654, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/nbclient/client.py", line 709, in async_execute
    await self.async_execute_cell(
  File "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/nbclient/client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/nbclient/client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
response = tt.run()
------------------


[31m---------------------------------------------------------------------------[39m
[31mConnectionError[39m                           Traceback (most recent call last)
[36mCell[39m[36m [39m[32mIn[3][39m[32m, line 1[39m
[32m----> [39m[32m1[39m response = [43mtt[49m[43m.[49m[43mrun[49m[43m([49m[43m)[49m

[36mFile [39m[32m~/work/benchtools/benchtools/benchtools/task.py:307[39m, in [36mTask.run[39m[34m(self, model, runner_type, api_url, logging_path)[39m
[32m    305[39m [38;5;28;01mmatch[39;00m runner_type:
[32m    306[39m     [38;5;28;01mcase[39;00m [33m"[39m[33mollama[39m[33m"[39m:
[32m--> [39m[32m307[39m         response: ChatResponse = [43mchat[49m[43m([49m[43mmodel[49m[43m=[49m[43mmodel[49m[43m,[49m[43m [49m[43mmessages[49m[43m=[49m[43m[[49m
[32m    308[39m [43m            [49m[43m{[49m
[32m    309[39m [43m              [49m[33;43m'[39;49m[33;43mrole[39;49m[33;43m'[39;49m[43m:[49m[43m [49m[33;43m'[39;49m[33;43muser[39;49m[33;43m'[39;49m[43m,[49m
[32m    310[39m [43m              [49m[33;43m'[39;49m[33;43mcontent[39;49m[33;43m'[39;49m[43m:[49m[43msub_task[49m[43m,[49m
[32m    311[39m [43m            [49m[43m}[49m[43m,[49m
[32m    312[39m [43m        [49m[43m][49m[43m)[49m
[32m    313[39m         [38;5;66;03m# print("response: " + response.message.content)[39;00m
[32m    314[39m         responses.append(response.message.content)

[36mFile [39m[32m/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/ollama/_client.py:365[39m, in [36mClient.chat[39m[34m(self, model, messages, tools, stream, think, logprobs, top_logprobs, format, options, keep_alive)[39m
[32m    318[39m [38;5;28;01mdef[39;00m[38;5;250m [39m[34mchat[39m(
[32m    319[39m   [38;5;28mself[39m,
[32m    320[39m   model: [38;5;28mstr[39m = [33m'[39m[33m'[39m,
[32m   (...)[39m[32m    330[39m   keep_alive: Optional[Union[[38;5;28mfloat[39m, [38;5;28mstr[39m]] = [38;5;28;01mNone[39;00m,
[32m    331[39m ) -> Union[ChatResponse, Iterator[ChatResponse]]:
[32m    332[39m [38;5;250m  [39m[33;03m"""[39;00m
[32m    333[39m [33;03m  Create a chat response using the requested model.[39;00m
[32m    334[39m 
[32m   (...)[39m[32m    363[39m [33;03m  Returns `ChatResponse` if `stream` is `False`, otherwise returns a `ChatResponse` generator.[39;00m
[32m    364[39m [33;03m  """[39;00m
[32m--> [39m[32m365[39m   [38;5;28;01mreturn[39;00m [38;5;28;43mself[39;49m[43m.[49m[43m_request[49m[43m([49m
[32m    366[39m [43m    [49m[43mChatResponse[49m[43m,[49m
[32m    367[39m [43m    [49m[33;43m'[39;49m[33;43mPOST[39;49m[33;43m'[39;49m[43m,[49m
[32m    368[39m [43m    [49m[33;43m'[39;49m[33;43m/api/chat[39;49m[33;43m'[39;49m[43m,[49m
[32m    369[39m [43m    [49m[43mjson[49m[43m=[49m[43mChatRequest[49m[43m([49m
[32m    370[39m [43m      [49m[43mmodel[49m[43m=[49m[43mmodel[49m[43m,[49m
[32m    371[39m [43m      [49m[43mmessages[49m[43m=[49m[38;5;28;43mlist[39;49m[43m([49m[43m_copy_messages[49m[43m([49m[43mmessages[49m[43m)[49m[43m)[49m[43m,[49m
[32m    372[39m [43m      [49m[43mtools[49m[43m=[49m[38;5;28;43mlist[39;49m[43m([49m[43m_copy_tools[49m[43m([49m[43mtools[49m[43m)[49m[43m)[49m[43m,[49m
[32m    373[39m [43m      [49m[43mstream[49m[43m=[49m[43mstream[49m[43m,[49m
[32m    374[39m [43m      [49m[43mthink[49m[43m=[49m[43mthink[49m[43m,[49m
[32m    375[39m [43m      [49m[43mlogprobs[49m[43m=[49m[43mlogprobs[49m[43m,[49m
[32m    376[39m [43m      [49m[43mtop_logprobs[49m[43m=[49m[43mtop_logprobs[49m[43m,[49m
[32m    377[39m [43m      [49m[38;5;28;43mformat[39;49m[43m=[49m[38;5;28;43mformat[39;49m[43m,[49m
[32m    378[39m [43m      [49m[43moptions[49m[43m=[49m[43moptions[49m[43m,[49m
[32m    379[39m [43m      [49m[43mkeep_alive[49m[43m=[49m[43mkeep_alive[49m[43m,[49m
[32m    380[39m [43m    [49m[43m)[49m[43m.[49m[43mmodel_dump[49m[43m([49m[43mexclude_none[49m[43m=[49m[38;5;28;43;01mTrue[39;49;00m[43m)[49m[43m,[49m
[32m    381[39m [43m    [49m[43mstream[49m[43m=[49m[43mstream[49m[43m,[49m
[32m    382[39m [43m  [49m[43m)[49m

[36mFile [39m[32m/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/ollama/_client.py:189[39m, in [36mClient._request[39m[34m(self, cls, stream, *args, **kwargs)[39m
[32m    185[39m         [38;5;28;01myield[39;00m [38;5;28mcls[39m(**part)
[32m    187[39m   [38;5;28;01mreturn[39;00m inner()
[32m--> [39m[32m189[39m [38;5;28;01mreturn[39;00m [38;5;28mcls[39m(**[38;5;28;43mself[39;49m[43m.[49m[43m_request_raw[49m[43m([49m[43m*[49m[43margs[49m[43m,[49m[43m [49m[43m*[49m[43m*[49m[43mkwargs[49m[43m)[49m.json())

[36mFile [39m[32m/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/ollama/_client.py:135[39m, in [36mClient._request_raw[39m[34m(self, *args, **kwargs)[39m
[32m    133[39m   [38;5;28;01mraise[39;00m ResponseError(e.response.text, e.response.status_code) [38;5;28;01mfrom[39;00m[38;5;250m [39m[38;5;28;01mNone[39;00m
[32m    134[39m [38;5;28;01mexcept[39;00m httpx.ConnectError:
[32m--> [39m[32m135[39m   [38;5;28;01mraise[39;00m [38;5;167;01mConnectionError[39;00m(CONNECTION_ERROR_MESSAGE) [38;5;28;01mfrom[39;00m[38;5;250m [39m[38;5;28;01mNone[39;00m

[31mConnectionError[39m: Failed to connect to Ollama. Please check that Ollama is downloaded, running and accessible. https://ollama.com/download

